name: Static Web Scraper Workflow

on:
  schedule:
    - cron: '0 10 * * *' # 每日 UTC 時間 10:00 執行
  workflow_dispatch: # 手動觸發

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    timeout-minutes: 30 # 設置超時時間為 30 分鐘

    steps:
      # 更新 GitHub Actions 資源（可選）
      - name: Update GitHub Actions resources
        run: sudo apt-get update && sudo apt-get install -y git

      # 檢出 GitHub Repository
      - name: Checkout repository
        uses: actions/checkout@v2

      # 設定 Python 環境
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      # 緩存 pip 套件以加速依賴安裝（可選）
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # 安裝所需的 Python 套件（確保 requirements.txt 存在）
      - name: Install dependencies
        run: |
          if [ -f requirements.txt ]; then
            python -m pip install --upgrade pip
            pip install --force-reinstall -r requirements.txt
          else
            echo "requirements.txt 不存在，跳過依賴安裝"
          fi

      # 執行靜態爬蟲程式（確保 static.py 存在）
      - name: Run static.py script
        run: |
          if [ -f static.py ]; then
            python static.py || echo "::error::Script execution failed"
          else
            echo "static.py 不存在，跳過執行"
          fi

      # 保存執行日誌到資料夾（失敗時）
      - name: Save logs to folder
        if: ${{ failure() }}
        run: |
          mkdir -p logs && mv *.log logs/ || echo "No log files found"

      # 上傳執行日誌（失敗時）
      - name: Upload logs as artifact
        if: ${{ failure() }}
        uses: actions/upload-artifact@v4 # 使用最新穩定版本 v4
        with:
          name: execution-logs
          path: logs/

      # 配置 SSH（用於推送到儲存庫）
      - name: Configure SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan github.com >> ~/.ssh/known_hosts

      # 提交爬蟲結果到 Repository（可選）
      - name: Commit and push results
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add static.json static.csv || echo "No changes to commit"
          git commit -m "Update scraped data" || echo "Nothing to commit"
          git push origin main || echo "Nothing to push"

      # 調試工具（僅在失敗時啟用）
      - name: Debug with tmate
        if: ${{ failure() }}
        uses: mxschmitt/action-tmate@v3
